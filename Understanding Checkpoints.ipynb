{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Starting/Stopping/Resuming Training\n",
    "## Understanding custom callbacks\n",
    "This notebook is for training and understanding purposes only. All algorithms and credits go to pyimagesearch.com, specifically https://www.pyimagesearch.com/2019/09/23/keras-starting-stopping-and-resuming-training/ and Adrian Rosebrock (A wonderful source and inspiration for Computer Vision and Deep Learning)\n",
    "\n",
    "As this notebook is for training and understanding purposes, rather than downloading the source code right away. The code will be typed in order to build \"muscle-memory\". Author-readable comments will appear from time to time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, there is a need to stop training prematurely. Some of the common reasons are : <br>\n",
    "\n",
    "1. Validation loss has plateau-ed\n",
    "2. No improvements of results have been observed\n",
    "3. Limited time on computing (GPU) resources\n",
    "\n",
    "While Keras's inbuilt learning rate scheduler class can address certain issues, they are typically contingent on number of epochs (e.g. LR/epochs). So how would we know what is the <br>\n",
    "\n",
    "1. proper initial learning rate and learning rate range?\n",
    "2. at what epochs do we start implementing learning rate decay?\n",
    "\n",
    "In any case, it is a good practice to save model's weight at specific interval and design a custom callback to achieve that purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general, custom callback classes inherit the tf.keras.callbacks.Callback class by caling <br>\n",
    "**super(<class_name>, self).__init__()**\n",
    "<br>\n",
    "\n",
    "This way, the custom callback classes contains all of Callback methods (including patience - number of epoch to wait*)\n",
    "<br>\n",
    "\n",
    "Under the custom callback classes, one can define pre-built function as following:\n",
    "<br>\n",
    "\n",
    "1. def on_{training|test|predict}_begin(self, logs=None):\n",
    "2. def on_{training|test|predict}_end(self, logs=None):\n",
    "3. def on_{training|test|predict}_batch_begin(self, batch, logs=None):\n",
    "4. def on_{training|test|predict}_batch_end(self, batch, logs=None):\n",
    "5. def on_epoch_begin(self, epochs, logs=None):\n",
    "6. def on_epoch_end(self, epochs, logs=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelBinarizer, LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D, ZeroPadding2D, Activation, Dense\n",
    "from tensorflow.keras.layers import Flatten, Input, add\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "class ResNet:\n",
    "    @staticmethod\n",
    "    def residual_module(data, K, stride, chanDim, red=False, reg=0.0001, bnEps=2e-5, bnMom=0.9):\n",
    "        #note that K here refers to the number of kernels, rather than the bacckend\n",
    "        shortcut = data\n",
    "        \n",
    "        # note that the batchnormalization in keras and tf.nn is different\n",
    "        # in Keras, there is an optional non-zero epsilon to ensure that it is not divisible by zero\n",
    "        # the momentum term is to take into account for moving average/variance\n",
    "        bn1 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(data)\n",
    "        act1 = Activation(\"relu\")(bn1)\n",
    "        \n",
    "        # there is also a l2 regularizer on the kernel\n",
    "        conv1 = Conv2D(int(K*0.25), (1,1), use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "        \n",
    "        bn2 = BatchNormalization(axis=chanDim, epsilon = bnEps, momentum = bnMom)(conv1)\n",
    "        act2 = Activation('relu')(bn2)\n",
    "        conv2 = Conv2D(int(K*0.25), (3,3), strides=stride, padding=\"same\", use_bias=False, kernel_regularizer=l2(reg))(act2)\n",
    "        \n",
    "        bn3 = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(conv2)\n",
    "        act3 = Activation(\"relu\")(bn3)\n",
    "        conv3 = Conv2D(K, (1, 1), use_bias=False,kernel_regularizer=l2(reg))(act3)\n",
    "        \n",
    "        if red:\n",
    "            shortcut = Conv2D(K, (1, 1), strides=stride, use_bias=False, kernel_regularizer=l2(reg))(act1)\n",
    "            \n",
    "        x = add([conv3, shortcut])\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    @staticmethod\n",
    "    def build(width, height, depth, classes, stages, filters, reg=0.0001, bnEps=2e-5, bnMom=0.9, dataset=\"cifar\"):\n",
    "        inputShape = (height, width, depth)\n",
    "        chanDim = -1\n",
    "        \n",
    "        if K.image_data_format() == \"channels_first\":\n",
    "            inputShape = (depth, height, width)\n",
    "            chanDim = 1\n",
    "            \n",
    "        inputs = Input(shape=inputShape)\n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(inputs)\n",
    "        x = Conv2D(filters[0], (3, 3), use_bias = False, padding = \"same\", kernel_regularizer=l2(reg))(x)\n",
    "        \n",
    "        for i in range(0, len(stages)):\n",
    "            stride = (1, 1) if i == 0 else (2, 2)\n",
    "            x = ResNet.residual_module(x, filters[i + 1], stride, chanDim, red=True, bnEps=bnEps, bnMom=bnMom)\n",
    "            \n",
    "            for j in range(0, stages[i] - 1):\n",
    "                x = ResNet.residual_module(x, filters[i + 1], (1, 1), chanDim, bnEps=bnEps, bnMom=bnMom)\n",
    "        \n",
    "        x = BatchNormalization(axis=chanDim, epsilon=bnEps, momentum=bnMom)(x)\n",
    "        x = Activation(\"relu\")(x)\n",
    "        x = AveragePooling2D((8,8))(x)\n",
    "        \n",
    "        x = Flatten()(x)\n",
    "        x = Dense(classes, kernel_regularizer=l2(reg))(x)\n",
    "        x = Activation(\"softmax\")(x)\n",
    "        \n",
    "        model = Model(inputs, x, name=\"resnet\")\n",
    "        \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import os\n",
    "\n",
    "class EpochCheckpoint(Callback):\n",
    "    def __init__(self, outputPath, every=5, startAt=0):\n",
    "        super(Callback, self).__init__()\n",
    "        \n",
    "        self.outputPath = outputPath\n",
    "        self.every = every\n",
    "        self.intEpoch = startAt\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if (self.intEpoch + 1) % self.every == 0:\n",
    "            p = os.path.sep.join([self.outputPath, \"epoch_{}.hdf5\".format(self.intEpoch+1)])\n",
    "            self.model.save(p, overwrite=True)\n",
    "            \n",
    "        self.intEpoch +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import BaseLogger\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "class TrainingMonitor(BaseLogger):\n",
    "    def __init__(self, figPath, jsonPath=None, startAt=0):\n",
    "        super(TrainingMonitor, self).__init__()\n",
    "        self.figPath = figPath\n",
    "        self.jsonPath = jsonPath\n",
    "        self.startAt = startAt\n",
    "        \n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.H = {}\n",
    "        \n",
    "        if self.jsonPath is not None:\n",
    "            if os.path.exists(self.jsonPath):\n",
    "                self.H = json.loads(open(self.jsonPath).read())\n",
    "                \n",
    "                if self.startAt > 0:\n",
    "                    for k in self.H.keys():\n",
    "                        self.H[k] = self.H[k][:self.startAt]\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "            # loop over the logs and update the loss, accuracy, etc for the entire training process\n",
    "            # in this case, history/logs is what being written on model.fit\n",
    "            for (k, v) in logs.items():\n",
    "                l = self.H.get(k, [])\n",
    "                l.append(float(v))\n",
    "                self.H[k] = l\n",
    "\n",
    "            # check to see if the training history should be serialized to file\n",
    "            if self.jsonPath is not None:\n",
    "                f = open(self.jsonPath, \"w\")\n",
    "                f.write(json.dumps(self.H))\n",
    "                f.close()\n",
    "\n",
    "            # ensure at least two epochs have passed before plotting\n",
    "            # (epoch starts at zero)\n",
    "            if len(self.H[\"loss\"]) > 1:\n",
    "                # plot the training loss and accuracy\n",
    "                N = np.arange(0, len(self.H[\"loss\"]))\n",
    "                plt.style.use(\"ggplot\")\n",
    "                plt.figure()\n",
    "                plt.plot(N, self.H[\"loss\"], label=\"train_loss\")\n",
    "                plt.plot(N, self.H[\"val_loss\"], label=\"val_loss\")\n",
    "                plt.plot(N, self.H[\"accuracy\"], label=\"train_acc\")\n",
    "                plt.plot(N, self.H[\"val_accuracy\"], label=\"val_acc\")\n",
    "                plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(len(self.H[\"loss\"])))\n",
    "                plt.xlabel(\"Epoch #\")\n",
    "                plt.ylabel(\"Loss/Accuracy\")\n",
    "                plt.legend()\n",
    "\n",
    "                # save the figure\n",
    "                plt.savefig(self.figPath)\n",
    "                plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading Fashion MNIST...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading Fashion MNIST...\")\n",
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "\n",
    "trainX = np.array([cv2.resize(x, (32, 32)) for x in trainX])\n",
    "testX = np.array([cv2.resize(x, (32, 32)) for x in testX])\n",
    "trainX = trainX.astype(\"float32\")/255.0\n",
    "testX = testX.astype(\"float32\")/255.0\n",
    "\n",
    "# two ways to expand the dimensions of the last axis\n",
    "trainX = tf.expand_dims(trainX, axis=-1)\n",
    "testX = testX.reshape((testX.shape[0], 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a label binarizer returns the index of one hot encoding\n",
    "lb = LabelBinarizer()\n",
    "\n",
    "trainY = lb.fit_transform(trainY)\n",
    "testY = lb.transform(testY)\n",
    "\n",
    "augmented = ImageDataGenerator(width_shift_range = 0.1, height_shift_range =0.1, horizontal_flip = True, fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-c\",\"--checkpoints\", required=True, help=\"path to output checkpoint directory\")\n",
    "# ap.add_argument(\"-m\",\"--model\", type=str, help=\"path to specific model checkpoint to load in hdf5\")\n",
    "# ap.add_argument(\"-s\",\"--start-epoch\",type=int, default=0, help=\"epoch to restart training at\")\n",
    "# args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] getting old learning rate: 0.10000000149011612\n",
      "[INFO] new learning rate: 0.009999999776482582\n"
     ]
    }
   ],
   "source": [
    "LR = 1e-1\n",
    "\n",
    "opt = SGD(lr = LR)\n",
    "model = ResNet.build(32,32,1,10,(9,9,9),(64,64,128,256),reg=0.0001)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "#print(\"[INFO] loading {}...\".format(\"saved_model\"))\n",
    "#model = load_model()\n",
    "\n",
    "print(\"[INFO] getting old learning rate: {}\".format(K.get_value(model.optimizer.lr)))\n",
    "K.set_value(model.optimizer.lr, 1e-2)\n",
    "print(\"[INFO] new learning rate: {}\".format(K.get_value(model.optimizer.lr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x229fea3f188>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [EpochCheckpoint(r\"C:\\Users\\Innovations\\Desktop\\AI\", every=5, startAt=0), TrainingMonitor(r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.png\",r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.json\", startAt=0)]\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(augmented.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY), steps_per_epoch = len(trainX)//128, epochs=80, callbacks=callbacks, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading saved_model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 468 steps, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "468/468 [==============================] - 80s 171ms/step - loss: 0.5554 - accuracy: 0.9425 - val_loss: 0.6041 - val_accuracy: 0.9269\n",
      "Epoch 2/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5528 - accuracy: 0.9439 - val_loss: 0.6037 - val_accuracy: 0.9268\n",
      "Epoch 3/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5491 - accuracy: 0.9453 - val_loss: 0.6047 - val_accuracy: 0.9280\n",
      "Epoch 4/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5505 - accuracy: 0.9438 - val_loss: 0.6057 - val_accuracy: 0.9269\n",
      "Epoch 5/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5489 - accuracy: 0.9447 - val_loss: 0.6067 - val_accuracy: 0.9267\n",
      "Epoch 6/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5482 - accuracy: 0.9450 - val_loss: 0.6053 - val_accuracy: 0.9272\n",
      "Epoch 7/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5475 - accuracy: 0.9452 - val_loss: 0.6039 - val_accuracy: 0.9277\n",
      "Epoch 8/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5480 - accuracy: 0.9457 - val_loss: 0.6034 - val_accuracy: 0.9264\n",
      "Epoch 9/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5456 - accuracy: 0.9460 - val_loss: 0.6033 - val_accuracy: 0.9282\n",
      "Epoch 10/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5454 - accuracy: 0.9465 - val_loss: 0.6035 - val_accuracy: 0.9270\n",
      "Epoch 11/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5451 - accuracy: 0.9466 - val_loss: 0.6030 - val_accuracy: 0.9285\n",
      "Epoch 12/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5446 - accuracy: 0.9459 - val_loss: 0.6042 - val_accuracy: 0.9281\n",
      "Epoch 13/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5441 - accuracy: 0.9468 - val_loss: 0.6050 - val_accuracy: 0.9272\n",
      "Epoch 14/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5433 - accuracy: 0.9480 - val_loss: 0.6033 - val_accuracy: 0.9281\n",
      "Epoch 15/30\n",
      "468/468 [==============================] - 74s 157ms/step - loss: 0.5461 - accuracy: 0.9451 - val_loss: 0.6056 - val_accuracy: 0.9262\n",
      "Epoch 16/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5439 - accuracy: 0.9465 - val_loss: 0.6029 - val_accuracy: 0.9276\n",
      "Epoch 17/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5423 - accuracy: 0.9471 - val_loss: 0.6046 - val_accuracy: 0.9269\n",
      "Epoch 18/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5436 - accuracy: 0.9471 - val_loss: 0.6035 - val_accuracy: 0.9269\n",
      "Epoch 19/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5423 - accuracy: 0.9472 - val_loss: 0.6032 - val_accuracy: 0.9280\n",
      "Epoch 20/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5423 - accuracy: 0.9470 - val_loss: 0.6052 - val_accuracy: 0.9265\n",
      "Epoch 21/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5405 - accuracy: 0.9489 - val_loss: 0.6055 - val_accuracy: 0.9260\n",
      "Epoch 22/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5418 - accuracy: 0.9475 - val_loss: 0.6036 - val_accuracy: 0.9269\n",
      "Epoch 23/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5399 - accuracy: 0.9480 - val_loss: 0.6034 - val_accuracy: 0.9271\n",
      "Epoch 24/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5400 - accuracy: 0.9491 - val_loss: 0.6037 - val_accuracy: 0.9277\n",
      "Epoch 25/30\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5388 - accuracy: 0.9486 - val_loss: 0.6034 - val_accuracy: 0.9263\n",
      "Epoch 26/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5387 - accuracy: 0.9477 - val_loss: 0.6045 - val_accuracy: 0.9279\n",
      "Epoch 27/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5390 - accuracy: 0.9489 - val_loss: 0.6027 - val_accuracy: 0.9266\n",
      "Epoch 28/30\n",
      "468/468 [==============================] - 75s 160ms/step - loss: 0.5380 - accuracy: 0.9489 - val_loss: 0.6039 - val_accuracy: 0.9272\n",
      "Epoch 29/30\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5360 - accuracy: 0.9501 - val_loss: 0.6046 - val_accuracy: 0.9288\n",
      "Epoch 30/30\n",
      "468/468 [==============================] - 74s 158ms/step - loss: 0.5373 - accuracy: 0.9485 - val_loss: 0.6038 - val_accuracy: 0.9280\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a48268288>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"[INFO] loading {}...\".format(\"saved_model\"))\n",
    "model = load_model(r\"C:/Users/Innovations/Desktop/AI/epoch_80.hdf5\")\n",
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "callbacks = [EpochCheckpoint(r\"C:\\Users\\Innovations\\Desktop\\AI\", every=5, startAt=80), TrainingMonitor(r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.png\",r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.json\", startAt=80)]\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(augmented.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY), steps_per_epoch = len(trainX)//128, epochs=30, callbacks=callbacks, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading saved_model...\n",
      "[INFO] training network...\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 468 steps, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "468/468 [==============================] - 81s 173ms/step - loss: 0.5556 - accuracy: 0.9423 - val_loss: 0.6258 - val_accuracy: 0.9213\n",
      "Epoch 2/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5563 - accuracy: 0.9408 - val_loss: 0.6345 - val_accuracy: 0.9189\n",
      "Epoch 3/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5552 - accuracy: 0.9408 - val_loss: 0.6282 - val_accuracy: 0.9172\n",
      "Epoch 4/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5529 - accuracy: 0.9423 - val_loss: 0.6149 - val_accuracy: 0.9199\n",
      "Epoch 5/20\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5506 - accuracy: 0.9418 - val_loss: 0.6164 - val_accuracy: 0.9198\n",
      "Epoch 6/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5499 - accuracy: 0.9425 - val_loss: 0.6863 - val_accuracy: 0.8946\n",
      "Epoch 7/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5470 - accuracy: 0.9436 - val_loss: 0.6414 - val_accuracy: 0.9127\n",
      "Epoch 8/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5449 - accuracy: 0.9437 - val_loss: 0.6250 - val_accuracy: 0.9153\n",
      "Epoch 9/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5436 - accuracy: 0.9449 - val_loss: 0.6062 - val_accuracy: 0.9258\n",
      "Epoch 10/20\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5413 - accuracy: 0.9437 - val_loss: 0.6190 - val_accuracy: 0.9207\n",
      "Epoch 11/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5385 - accuracy: 0.9457 - val_loss: 0.6078 - val_accuracy: 0.9231\n",
      "Epoch 12/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5389 - accuracy: 0.9450 - val_loss: 0.6164 - val_accuracy: 0.9223\n",
      "Epoch 13/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5384 - accuracy: 0.9446 - val_loss: 0.6051 - val_accuracy: 0.9257\n",
      "Epoch 14/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5360 - accuracy: 0.9461 - val_loss: 0.6193 - val_accuracy: 0.9204\n",
      "Epoch 15/20\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5353 - accuracy: 0.9454 - val_loss: 0.6146 - val_accuracy: 0.9226\n",
      "Epoch 16/20\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5324 - accuracy: 0.9470 - val_loss: 0.6223 - val_accuracy: 0.9189\n",
      "Epoch 17/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5284 - accuracy: 0.9475 - val_loss: 0.6166 - val_accuracy: 0.9178\n",
      "Epoch 18/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5276 - accuracy: 0.9469 - val_loss: 0.5994 - val_accuracy: 0.9271\n",
      "Epoch 19/20\n",
      "468/468 [==============================] - 73s 156ms/step - loss: 0.5257 - accuracy: 0.9478 - val_loss: 0.5955 - val_accuracy: 0.9268\n",
      "Epoch 20/20\n",
      "468/468 [==============================] - 73s 157ms/step - loss: 0.5245 - accuracy: 0.9480 - val_loss: 0.5961 - val_accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22a8a35c6c8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"val_loss\", factor = 0.5, patience=5, min_lr=0.00001)\n",
    "print(\"[INFO] loading {}...\".format(\"saved_model\"))\n",
    "model = load_model(r\"C:/Users/Innovations/Desktop/AI/epoch_110.hdf5\")\n",
    "K.set_value(model.optimizer.lr, 1e-2)\n",
    "callbacks = [EpochCheckpoint(r\"C:\\Users\\Innovations\\Desktop\\AI\", every=5, startAt=110), TrainingMonitor(r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.png\",r\"C:\\Users\\Innovations\\Desktop\\AI\\resnet_fashion_mnist.json\", startAt=110), reduce_lr]\n",
    "print(\"[INFO] training network...\")\n",
    "model.fit(augmented.flow(trainX, trainY, batch_size=128), validation_data=(testX, testY), steps_per_epoch = len(trainX)//128, epochs=20, callbacks=callbacks, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
